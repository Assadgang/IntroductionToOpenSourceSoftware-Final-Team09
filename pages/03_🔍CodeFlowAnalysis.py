# pages/03_ğŸ”CodeFlowAnalysis.py
# ---------------------------------------------------
# ëª¨ë“ˆ ì„í¬íŠ¸
# ---------------------------------------------------
import streamlit as st
import json
import requests
from pathlib import Path
import module.github as github
import module.gpt as gpt
import module.gemini as gemini

# ---------------------------------------------------
# í˜ì´ì§€ ì„¤ì •
# ---------------------------------------------------
st.set_page_config(
    page_title="Code Flow Analysis",
    page_icon="ğŸ”",
    layout="wide"
)

# ---------------------------------------------------
# ì„¸ì…˜ ìƒíƒœ ë¶ˆëŸ¬ì˜¤ê¸°
# ---------------------------------------------------
options = st.session_state.get("options", {})
contents = st.session_state.get("contents", {})

# ---------------------------------------------------
# ì‚¬ì´ë“œë°” (API, URL ì…ë ¥)
# ---------------------------------------------------
st.sidebar.title("Input")
api_key = st.sidebar.text_input(
    "ğŸ”‘ GPT/Gemini API token", 
    value=options.get("api_key", ""), 
    type="password", 
    disabled=True,
    help="Set in Home page"
)
repository_url = st.sidebar.text_input(
    "ğŸ“Š Github Repository URL", 
    value=options.get("repository_url", ""), 
    disabled=True,
    help="Set in Home page"
)

# ì–¸ì–´ ì„ íƒ
language = st.sidebar.selectbox(
    "Response Language",
    ["English", "Korean"],
    index=1 if options.get("language") == "Korean" else 0
)

st.sidebar.divider()

# ë ˆí¬ì§€í† ë¦¬ ì •ë³´ í‘œì‹œ
if repository_url:
    try:
        owner, repo = repository_url.replace("https://github.com/", "").split("/")[:2]
        st.sidebar.success(f"âœ… Repository: `{owner}/{repo}`")
    except:
        st.sidebar.error("âŒ Invalid URL format")

# ---------------------------------------------------
# í—¬í¼ í•¨ìˆ˜ë“¤
# ---------------------------------------------------
def parse_github_url(url: str) -> dict:
    """GitHub URLì—ì„œ ownerì™€ repo ì¶”ì¶œ"""
    if not url:
        return None
    try:
        parts = url.replace("https://github.com/", "").split("/")
        return {
            "owner": parts[0],
            "repo": parts[1]
        }
    except:
        return None


def fetch_repository_tree(owner: str, repo: str, branch: str = "main") -> dict:
    """GitHub APIë¡œ ì €ì¥ì†Œì˜ íŒŒì¼ íŠ¸ë¦¬ ê°€ì ¸ì˜¤ê¸°"""
    # GitHub API ì—”ë“œí¬ì¸íŠ¸
    url = f"https://api.github.com/repos/{owner}/{repo}/git/trees/{branch}?recursive=1"
    
    try:
        response = requests.get(url, timeout=15)
        
        # main ë¸Œëœì¹˜ ì‹¤íŒ¨ ì‹œ master ì‹œë„
        if response.status_code in [401, 404]:
            url = f"https://api.github.com/repos/{owner}/{repo}/git/trees/master?recursive=1"
            response = requests.get(url, timeout=15)
        
        response.raise_for_status()
        data = response.json()
        
        # íŒŒì¼ íŠ¸ë¦¬ë¥¼ ê³„ì¸µ êµ¬ì¡°ë¡œ ë³€í™˜
        tree = {}
        
        for item in data.get("tree", []):
            path = item["path"]
            item_type = item["type"]
            
            # ë¶ˆí•„ìš”í•œ íŒŒì¼/í´ë” í•„í„°ë§
            ignore_patterns = ['.git', '__pycache__', 'node_modules', '.venv', 'venv', 
                             '.idea', '.vscode', 'dist', 'build', '.DS_Store']
            
            if any(ignore in path for ignore in ignore_patterns):
                continue
            
            # ê²½ë¡œë¥¼ ê³„ì¸µ êµ¬ì¡°ë¡œ ë³€í™˜
            parts = path.split("/")
            current = tree
            
            for i, part in enumerate(parts):
                if i == len(parts) - 1:
                    # íŒŒì¼ ë˜ëŠ” ë””ë ‰í† ë¦¬ ì¶”ê°€
                    if item_type == "blob":
                        current[part] = {
                            "type": "file",
                            "size": item.get("size", 0),
                            "extension": Path(part).suffix,
                            "path": path
                        }
                    else:
                        if part not in current:
                            current[part] = {
                                "type": "directory",
                                "contents": {}
                            }
                else:
                    # ì¤‘ê°„ ë””ë ‰í† ë¦¬ ìƒì„±
                    if part not in current:
                        current[part] = {
                            "type": "directory",
                            "contents": {}
                        }
                    current = current[part].get("contents", current[part])
        
        return tree
    
    except requests.exceptions.RequestException as e:
        st.error(f"âŒ GitHub API Error: {str(e)}")
        return {}


def fetch_file_content(owner: str, repo: str, file_path: str, branch: str = "main") -> str:
    """GitHub APIë¡œ íŠ¹ì • íŒŒì¼ì˜ ë‚´ìš© ê°€ì ¸ì˜¤ê¸°"""
    url = f"https://api.github.com/repos/{owner}/{repo}/contents/{file_path}?ref={branch}"
    
    try:
        response = requests.get(url, timeout=10)
        
        # main ë¸Œëœì¹˜ ì‹¤íŒ¨ ì‹œ master ì‹œë„
        if response.status_code in [401, 404]:
            url = f"https://api.github.com/repos/{owner}/{repo}/contents/{file_path}?ref=master"
            response = requests.get(url, timeout=10)
        
        response.raise_for_status()
        data = response.json()
        
        # Base64 ë””ì½”ë”©í•˜ì—¬ íŒŒì¼ ë‚´ìš© ë°˜í™˜
        import base64
        content = base64.b64decode(data["content"]).decode("utf-8")
        return content
    
    except Exception as e:
        return f"# Error fetching file: {str(e)}"


def find_source_files(tree: dict, extensions: list, current_path: str = "") -> list:
    """íŒŒì¼ íŠ¸ë¦¬ì—ì„œ íŠ¹ì • í™•ì¥ìì˜ íŒŒì¼ ê²½ë¡œ ì°¾ê¸°"""
    files = []
    
    for name, value in tree.items():
        if isinstance(value, dict):
            if value.get("type") == "file":
                # í™•ì¥ì ë§¤ì¹­ í™•ì¸
                if any(name.endswith(ext) for ext in extensions):
                    full_path = f"{current_path}/{name}" if current_path else name
                    files.append((name, value.get("path", full_path)))
            
            elif value.get("type") == "directory":
                # í•˜ìœ„ ë””ë ‰í† ë¦¬ ì¬ê·€ íƒìƒ‰
                sub_path = f"{current_path}/{name}" if current_path else name
                files.extend(find_source_files(value.get("contents", {}), extensions, sub_path))
    
    return files


def count_files(tree: dict) -> int:
    """íŒŒì¼ íŠ¸ë¦¬ì˜ ì´ íŒŒì¼ ê°œìˆ˜ ê³„ì‚°"""
    count = 0
    for key, value in tree.items():
        if isinstance(value, dict):
            if value.get("type") == "file":
                count += 1
            elif value.get("type") == "directory":
                count += count_files(value.get("contents", {}))
    return count


# ---------------------------------------------------
# ì‚¬ì „ ì¡°ê±´ í™•ì¸
# ---------------------------------------------------
if not (options.get("api_key") and options.get("repository_url")):
    st.error("â›” API Token ê³¼ GitHub URLì„ ì…ë ¥í•´ì•¼ ì´ í˜ì´ì§€ë¥¼ ì´ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
    st.stop()

# API í‚¤ ìœ íš¨ì„± ê²€ì‚¬
with st.spinner("Validating API key..."):
    if not gemini.api_check(api_key):
        st.error("âŒ Invalid API Key. Please check your Gemini API key.")
        st.stop()

# GitHub URL íŒŒì‹±
parsed_url = parse_github_url(repository_url)
if not parsed_url:
    st.error("âŒ Invalid GitHub URL format")
    st.stop()

owner = parsed_url["owner"]
repo = parsed_url["repo"]

# ---------------------------------------------------
# í˜ì´ì§€ í—¤ë” (UI ê°œì„ )
# ---------------------------------------------------
st.title("ğŸ“¡ Repositorie Radar")
st.write("GitHub ì €ì¥ì†Œë¥¼ ìë™ ë¶„ì„í•˜ëŠ” ì›¹ ê¸°ë°˜ ì˜¤í”ˆì†ŒìŠ¤ íƒìƒ‰ ë„êµ¬ì…ë‹ˆë‹¤.")
st.divider()

st.title("ğŸ” CodeFlow Analysis")

# ---------------------------------------------------
# ë ˆí¬ì§€í† ë¦¬ ì •ë³´ í‘œì‹œ
# ---------------------------------------------------
with st.expander("ğŸ“¦ Repository Information", expanded=False):
    col1, col2 = st.columns(2)
    with col1:
        st.markdown(f"**Repository URL:**")
        st.code(repository_url, language=None)
    with col2:
        st.markdown(f"**Owner:** `{owner}`")
        st.markdown(f"**Repository:** `{repo}`")

st.divider()

# ---------------------------------------------------
# ë¶„ì„ ì˜µì…˜ ì„¤ì •
# ---------------------------------------------------
st.header("âš™ï¸ Analysis Options")

col1, col2 = st.columns([1, 1])

with col1:
    analysis_depth = st.selectbox(
        "Analysis Depth",
        ["Basic (File Tree Only)", "Detailed (Include Source Code)"],
        help="Basic: Analyze file structure only. Detailed: Include actual source code."
    )

with col2:
    max_files = st.slider(
        "Maximum Files to Analyze",
        min_value=1,
        max_value=10,
        value=5,
        help="Number of source files to include (Detailed mode only)"
    )

# ë¶„ì„í•  íŒŒì¼ í™•ì¥ì ì„ íƒ
file_extensions = st.multiselect(
    "File Extensions to Analyze (Detailed mode)",
    [".py", ".js", ".java", ".cpp", ".ts", ".go", ".rs", ".rb", ".php"],
    default=[".py"],
    help="Select file types to include in detailed analysis"
)

# ë¸Œëœì¹˜ ì„ íƒ
branch = st.text_input(
    "Branch",
    value="main",
    help="Branch to analyze (default: main)"
)

st.divider()

# ---------------------------------------------------
# AI ë¶„ì„ ì„¹ì…˜ (UI ê°œì„  - headerë§Œ ë³€ê²½)
# ---------------------------------------------------
st.header("ğŸ¤– AI Comment")

if st.button("ğŸ” Start Code Flow Analysis", type="primary", use_container_width=True):
    
    # 1ë‹¨ê³„: GitHubì—ì„œ íŒŒì¼ íŠ¸ë¦¬ ê°€ì ¸ì˜¤ê¸°
    with st.status("ğŸ“ Fetching repository structure from GitHub...", expanded=True) as status:
        st.write(f"Repository: {owner}/{repo}")
        st.write(f"Branch: {branch}")
        st.write("Fetching file tree via GitHub API...")
        
        try:
            file_tree = fetch_repository_tree(owner, repo, branch)
            
            if not file_tree:
                st.error("âŒ Failed to fetch repository structure. Check if repository is public and URL is correct.")
                st.stop()
            
            file_count = count_files(file_tree)
            st.write(f"âœ… Found {file_count} files")
            
            # íŒŒì¼ íŠ¸ë¦¬ ë¯¸ë¦¬ë³´ê¸°
            with st.expander("ğŸ“‚ File Tree Preview", expanded=False):
                st.json(file_tree)
            
            status.update(label=f"âœ… File tree loaded! ({file_count} files)", state="complete")
        
        except Exception as e:
            st.error(f"âŒ Error loading file tree: {str(e)}")
            st.stop()
    
    # 2ë‹¨ê³„: ì†ŒìŠ¤ ì½”ë“œ ê°€ì ¸ì˜¤ê¸° (Detailed ëª¨ë“œì¼ ê²½ìš°)
    source_code = None
    
    if analysis_depth == "Detailed (Include Source Code)":
        with st.status("ğŸ’» Fetching source code from GitHub...", expanded=True) as status:
            st.write(f"Looking for files with extensions: {', '.join(file_extensions)}")
            
            try:
                # íŒŒì¼ íŠ¸ë¦¬ì—ì„œ í•´ë‹¹ í™•ì¥ì íŒŒì¼ ì°¾ê¸°
                source_files = find_source_files(file_tree, file_extensions)
                
                if not source_files:
                    st.warning(f"âš ï¸ No files found with extensions: {file_extensions}")
                    st.info("Continuing with file tree analysis only...")
                else:
                    source_code = {}
                    files_fetched = 0
                    
                    # ê° íŒŒì¼ì˜ ë‚´ìš© ê°€ì ¸ì˜¤ê¸°
                    for filename, filepath in source_files[:max_files]:
                        st.write(f"ğŸ“¥ Fetching: `{filepath}`")
                        
                        content = fetch_file_content(owner, repo, filepath, branch)
                        
                        if content and not content.startswith("# Error"):
                            # íŒŒì¼ ë‚´ìš© 2000ì ì œí•œ
                            source_code[filepath] = content[:2000]
                            files_fetched += 1
                            st.write(f"âœ… Fetched: `{filepath}` ({len(content)} chars)")
                        else:
                            st.warning(f"âš ï¸ Could not fetch: `{filepath}`")
                        
                        if files_fetched >= max_files:
                            break
                    
                    if source_code:
                        st.write(f"âœ… Successfully fetched {len(source_code)} files")
                    else:
                        st.warning("âš ï¸ No source files fetched. Using file tree only.")
                
                status.update(label=f"âœ… Fetched {len(source_code) if source_code else 0} source files", state="complete")
            
            except Exception as e:
                st.warning(f"âš ï¸ Could not fetch source code: {str(e)}")
                st.info("Continuing with file tree analysis only...")
    
    # 3ë‹¨ê³„: AI ë¶„ì„ ì‹¤í–‰
    with st.status("ğŸ¤– Analyzing code flow with Gemini AI...", expanded=True) as status:
        st.write("Sending data to Gemini AI...")
        st.write(f"Language: {language}")
        st.write(f"Mode: {analysis_depth}")
        st.write(f"Files in analysis: {count_files(file_tree)}")
        if source_code:
            st.write(f"Source code samples: {len(source_code)}")
        
        try:
            # Gemini API í˜¸ì¶œ
            result = gemini.api_code_flow_analysis(
                _key=api_key,
                _file_tree=file_tree,
                _source_code=source_code,
                _language=language
            )
            
            if result.startswith("Error:"):
                st.error(f"âŒ Analysis failed: {result}")
                st.stop()
            
            status.update(label="âœ… Analysis complete!", state="complete")
        
        except Exception as e:
            st.error(f"âŒ AI Analysis error: {str(e)}")
            st.stop()
    
    # 4ë‹¨ê³„: ë¶„ì„ ê²°ê³¼ í‘œì‹œ
    st.success("âœ… Code Flow Analysis Complete!")
    
    st.divider()
    st.markdown("## ğŸ“Š Analysis Results")
    
    # ê²°ê³¼ë¥¼ íƒ­ìœ¼ë¡œ êµ¬ë¶„í•˜ì—¬ í‘œì‹œ
    tab1, tab2, tab3 = st.tabs(["ğŸ“ Full Analysis", "ğŸ“¥ Download", "â„¹ï¸ Info"])
    
    with tab1:
        st.markdown(result)
    
    with tab2:
        st.markdown("### Download Analysis Report")
        
        # ë¶„ì„ ë³´ê³ ì„œ ìƒì„±
        from datetime import datetime
        timestamp = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
        
        report = f"""# Code Flow Analysis Report

**Repository:** {repository_url}
**Owner:** {owner}
**Repository Name:** {repo}
**Branch:** {branch}
**Analysis Date:** {timestamp}
**Language:** {language}
**Analysis Mode:** {analysis_depth}
**Files Analyzed:** {count_files(file_tree)}

---

{result}

---

## File Tree Structure
```json
{json.dumps(file_tree, indent=2, ensure_ascii=False)}
```

---

*Generated by Repository Radar using Gemini AI*
"""
        
        col1, col2 = st.columns(2)
        
        # ë§ˆí¬ë‹¤ìš´ íŒŒì¼ ë‹¤ìš´ë¡œë“œ
        with col1:
            st.download_button(
                label="ğŸ“¥ Download as Markdown",
                data=report,
                file_name=f"code_flow_analysis_{owner}_{repo}.md",
                mime="text/markdown",
                use_container_width=True
            )
        
        # í…ìŠ¤íŠ¸ íŒŒì¼ ë‹¤ìš´ë¡œë“œ
        with col2:
            st.download_button(
                label="ğŸ“¥ Download as Text",
                data=result,
                file_name=f"code_flow_analysis_{owner}_{repo}.txt",
                mime="text/plain",
                use_container_width=True
            )
    
    with tab3:
        st.markdown("""
        ### ğŸ“Š What is Code Flow Analysis?
        
        Code Flow Analysis provides:
        
        1. **Execution Flow**: Step-by-step path from entry point
        2. **Module Dependencies**: How modules interact
        3. **Data Flow**: How data moves through the app
        4. **Key Functions**: Important functions and roles
        5. **Interaction Diagram**: Component relationships
        6. **Critical Paths**: Performance bottlenecks
        7. **Recommendations**: Improvement suggestions
        
        ### ğŸ¯ Use Cases
        
        - Understanding unfamiliar codebases
        - Planning refactoring
        - Identifying bottlenecks
        - Documenting architecture
        - Code reviews
        
        ### ğŸ”„ Analysis Process
        
        1. **Fetch from GitHub**: Automatically fetch repository structure
        2. **Parse Structure**: Convert to hierarchical tree
        3. **Fetch Source**: Download key source files (Detailed mode)
        4. **AI Analysis**: Gemini analyzes flow and dependencies
        5. **Generate Report**: Create comprehensive analysis
        """)

# ---------------------------------------------------
# ì¶”ê°€ ê¸°ëŠ¥ ë° íŒ
# ---------------------------------------------------
st.divider()

with st.expander("ğŸ’¡ Tips for Better Analysis"):
    st.markdown("""
    **For Best Results:**
    
    1. **Use Public Repositories**: GitHub API works best with public repos
    2. **Check Branch Name**: Default is 'main', but some repos use 'master'
    3. **Select Relevant Extensions**: Focus on main language files
    4. **Limit File Count**: 3-5 files recommended for detailed analysis
    5. **Include Entry Points**: Files like `main.py`, `app.py`, `index.js`
    
    **What Gets Analyzed:**
    
    - ğŸ“ Directory structure and organization
    - ğŸ”— Module imports and dependencies
    - ğŸ“Š Function call chains
    - ğŸ”„ Data flow between components
    - âš¡ Performance critical paths
    - ğŸ¯ Entry points and initialization
    
    **GitHub API Limits:**
    
    - Rate limit: 60 requests/hour (unauthenticated)
    - Repository must be public
    - Large files may be truncated
    """)

# ---------------------------------------------------
# footer
# ---------------------------------------------------
st.divider()
st.caption(f"Powered by Gemini AI | Code Flow Analysis v2.0 | Repository: {owner}/{repo}")